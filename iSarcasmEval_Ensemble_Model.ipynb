{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ay1RWNLe-mq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXrgRvkLfCS6"
      },
      "source": [
        "# Import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UoC0rRJvbUe"
      },
      "outputs": [],
      "source": [
        "import torch.nn as nn\n",
        "import torch\n",
        "from torch.utils.data.sampler import BatchSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_qFAPADu8b4"
      },
      "outputs": [],
      "source": [
        "import  json"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dNDpLk7ClGlk"
      },
      "outputs": [],
      "source": [
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rkyo73_koUWI"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm_notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rfudWy58lw2J"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vNIH-Uxos2F_"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os\n",
        "from sklearn.utils.class_weight import compute_class_weight"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HQEpsCsHrSMr"
      },
      "outputs": [],
      "source": [
        "import random\n",
        "import time\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "stfRxXGxnoUs"
      },
      "outputs": [],
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n4RYuyq9fFoN"
      },
      "outputs": [],
      "source": [
        "import csv\n",
        "import json\n",
        "from sklearn import *\n",
        "import json, sys, regex\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from numpy.random import RandomState\n",
        "import pandas as pd\n",
        "import os\n",
        "import re\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download(\"all\")\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBzhj6rfiAqd"
      },
      "outputs": [],
      "source": [
        "pip install wget"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aTQ4LmWoh6Ut"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wget\n",
        "import gzip\n",
        "import shutil"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hkhc10wNrGt"
      },
      "outputs": [],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-JyEpYUGTxqG"
      },
      "outputs": [],
      "source": [
        "from transformers import AdamW"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8wBRd5zXAkX"
      },
      "outputs": [],
      "source": [
        "!wget https://huggingface.co/UBC-NLP/MARBERT/resolve/main/MARBERT_pytorch_verison.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9FYvgJevXAkY"
      },
      "outputs": [],
      "source": [
        "!tar -xvf MARBERT_pytorch_verison.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwxvO8pu1nu_"
      },
      "outputs": [],
      "source": [
        "!pip install GPUtil pytorch_pretrained_bert transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x4giRzM7NtHJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "import transformers\n",
        "from transformers import AutoModel, BertTokenizerFast\n",
        "from sklearn.metrics import accuracy_score, f1_score, recall_score, precision_score, classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PYh4RFPzb1Ai"
      },
      "outputs": [],
      "source": [
        "!mkdir -p  isarcastic\n",
        "!cp \"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_train.csv\"  ./isarcastic/isarcastic_Ar_train.csv\n",
        "!cp \"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_test1.csv\"  ./isarcastic/isarcastic_Ar_test1.csv\n",
        "!cp \"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_test2.csv\"  ./isarcastic/isarcastic_Ar_test2.csv"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_train.csv\"  ./isarcastic/isarcastic_Ar_train.cs\n"
      ],
      "metadata": {
        "id": "lGxKAmAf5DHT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/gdrive/MyDrive/Master/Dataset/TestingData/task_A_AR_test.csv\"  ./isarcastic/task_A_AR_test.csv"
      ],
      "metadata": {
        "id": "uKRoX4jt9ZZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file2 = './isarcastic/task_A_AR_test.csv'"
      ],
      "metadata": {
        "id": "3aZaKR5n9SUh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GQWKMrXPXAkc"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"your device \", device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECMqsLVkhVcD"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('./isarcastic/isarcastic_Ar_train.csv', sep=\",\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s6fbwlPlhaLE"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv('isarcastic/isarcastic_Ar_test1.csv', sep=\",\")\n",
        "df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6sbzlxbf6h4"
      },
      "outputs": [],
      "source": [
        "\n",
        "config={\"task_name\": \"isarcastic_MARBERT\", #output directory name\n",
        "             \"data_dir\": \"./\", #data directory\n",
        "             \"checkpoint_dir\": \"./\",\n",
        "             \"train_file\": \"isarcastic/isarcastic_Ar_train.csv\", #train file path\n",
        "             \"dev_file\": \"isarcastic/isarcastic_Ar_test1.csv\", #dev file path or test file path\n",
        "             \"test_file\": \"isarcastic/isarcastic_Ar_test2.csv\", #dev file path or test file path\n",
        "        \n",
        "\n",
        "             \"pretrained_model_path\": 'MARBERT_pytorch_verison', #MARBERT checkpoint path\n",
        "            #  \"fine_tuned_model_path\" : \"/gdrive/MyDrive/Master/Dataset/isarcasticisarcastic_MARBERT_bert_ckpt/model_5\",\n",
        "             \"epochs\": 1, #number of epochs\n",
        "             \"content_col\": \"tweet\", #text column\n",
        "             \"label_col\": \"sarcastic\", #label column\n",
        "             \"lr\": 2e-06, #learning rate\n",
        "              \"max_seq_length\": 64, #max sequance length\n",
        "              \"batch_size\": 32, #batch shize\n",
        "              \"sortby\":\"val_acc\"} #sort results based on val_acc or val_f1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfRA9rQygBA0"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------\n",
        "print (\"[INFO] step (1) load train_test config file\")\n",
        "task_name = config[\"task_name\"]\n",
        "content_col = config[\"content_col\"]\n",
        "label_col = config[\"label_col\"]\n",
        "train_file = config[\"data_dir\"]+config[\"train_file\"]\n",
        "dev_file = config[\"data_dir\"]+config[\"dev_file\"]\n",
        "test_file = config[\"data_dir\"]+config[\"test_file\"]\n",
        "sortby = config[\"sortby\"]\n",
        "max_seq_length= int(config[\"max_seq_length\"])\n",
        "batch_size = int(config[\"batch_size\"])\n",
        "lr_var = float(config[\"lr\"])\n",
        "model_path = config['pretrained_model_path']\n",
        "num_epochs = config['epochs'] # Number of training epochs (authors recommend between 2 and 4)\n",
        "global label2idx_file\n",
        "label2idx_file = config[\"data_dir\"]+config[\"task_name\"]+\"_labels-dict.json\"\n",
        "#-------------------------------------------------------\n",
        "print (\"[INFO] step (2) convert labels2index\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Kl3V7v5MgFMU"
      },
      "outputs": [],
      "source": [
        "\n",
        "def create_label2ind_file(file, label_col):\n",
        "\tlabels_json={}\n",
        "\t#load train_dev_test file\n",
        "\tdf = pd.read_csv(file, sep=\",\")\n",
        "\tdf.head(5)\n",
        "\t#get labels and sort it A-Z\n",
        "\tlabels = df[label_col].unique()\n",
        "\tlabels.sort()\n",
        "\t#convert labels to indexes\n",
        "\tfor idx in range(0, len(labels)):\n",
        "\t\tlabels_json[labels[idx]]=idx\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oz2LPU-RjGke"
      },
      "outputs": [],
      "source": [
        "create_label2ind_file(train_file, label_col)\n",
        "print (label2idx_file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7gXCLlMnIGh"
      },
      "outputs": [],
      "source": [
        "#---------------------------------------------------------\n",
        "print (\"[INFO] step (3) check checkpoit directory and report file\")\n",
        "ckpt_dir = config[\"checkpoint_dir\"]+task_name+\"_bert_ckpt/\"\n",
        "report = ckpt_dir+task_name+\"_report.tsv\"\n",
        "sorted_report = ckpt_dir+task_name+\"_report_sorted.tsv\"\n",
        "if not os.path.exists(ckpt_dir):\n",
        "  os.mkdir(ckpt_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dsAf31i9nLDP"
      },
      "outputs": [],
      "source": [
        "#-------------------------------------------------------\n",
        "print (\"[INFO] step (4) load label to number dictionary\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbYBrueXnacr"
      },
      "outputs": [],
      "source": [
        "x =  '{ \"0\":0, \"1\":1}'\n",
        "y = json.loads(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I5CVBGN_noLG"
      },
      "outputs": [],
      "source": [
        "lab2ind = json.loads(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w9F2ow4eoYOR"
      },
      "outputs": [],
      "source": [
        "print (\"[INFO] train_file\", train_file)\n",
        "print (\"[INFO] dev_file\", dev_file)\n",
        "print (\"[INFO] num_epochs\", num_epochs)\n",
        "print (\"[INFO] model_path\", model_path)\n",
        "print (\"max_seq_length\", max_seq_length, \"batch_size\", batch_size)\n",
        "#-------------------------------------------------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "__N7V2Ptgecx"
      },
      "outputs": [],
      "source": [
        "def data_prepare(file_path, lab2ind, content_col, label_col, MAX_LEN):\n",
        "  df = pd.read_csv(file_path, delimiter=',', header=0)\n",
        "  df = df[df[content_col].notnull()]\n",
        "  df = df[df[label_col].notnull()]\n",
        "  print(\"Data size \", df.shape)\n",
        "  sentences = df[content_col].values\n",
        "  print (\"The first sentence:\")\n",
        "  print (sentences[0])\n",
        "  labels = df[label_col].values\n",
        "  print(labels)\n",
        "  labels = [lab2ind[ str(i)] for i in labels]\n",
        "  return sentences,labels"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prepare2(file_path, lab2ind, content_col, MAX_LEN):\n",
        "  df = pd.read_csv(file_path, delimiter=',', header=0)\n",
        "  df = df[df[content_col].notnull()]\n",
        "  print(\"Data size \", df.shape)\n",
        "  sentences = df[content_col].values\n",
        "  print (\"The first sentence:\")\n",
        "  print (sentences[0])\n",
        "\n",
        "  return sentences"
      ],
      "metadata": {
        "id": "kvVw-y8t9uoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def data_prepare3(file_path, lab2ind, content_col_0, content_col_1, label_col, MAX_LEN):\n",
        "  df = pd.read_csv(file_path, delimiter=',', header=0)\n",
        "  print(\"df before notnull\", df)\n",
        "  df = df[df[content_col_0].notnull()]\n",
        "  df = df[df[content_col_1].notnull()]\n",
        "  print(\"df after notnull\", df)\n",
        "  print(\"Data size \", df.shape)\n",
        "  sentences_0 = df[content_col_0].values\n",
        "  sentences_1 = df[content_col_1].values\n",
        "  sentences_0 = [\"[CLS] \" + sentence+ \" [SEP]\" for sentence in sentences_0]\n",
        "  sentences_1 = [\"[CLS] \" + sentence+ \" [SEP]\" for sentence in sentences_1]\n",
        "  print (\"The first sentence:\")\n",
        "  print (sentences_0[0])\n",
        "  print (sentences_1[0])\n",
        "  \n",
        "  return sentences_0,sentences_1\n"
      ],
      "metadata": {
        "id": "WPp8ePrXAZJk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file3"
      ],
      "metadata": {
        "id": "5Voc-hcPBkSv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs03,test_inputs13 "
      ],
      "metadata": {
        "id": "Ob5zgnwiBu65"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs03,test_inputs13 = data_prepare3('isarcastic/task_C_AR_test.csv', lab2ind, \"text_0\", \"text_1\", label_col,max_seq_length)\n"
      ],
      "metadata": {
        "id": "CO2eEtDhA5Uj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "v6AdZVc2BrQE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs2 = data_prepare2(test_file2, lab2ind,'text', max_seq_length)"
      ],
      "metadata": {
        "id": "pVDcHvo592pH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(test_inputs2))"
      ],
      "metadata": {
        "id": "PaAChwGjjgTl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sjhfy-e9gw2F"
      },
      "outputs": [],
      "source": [
        "train_inputs, train_labels = data_prepare(train_file, lab2ind,content_col, label_col, max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sru8ipJpg1B_"
      },
      "outputs": [],
      "source": [
        "validation_inputs, validation_labels = data_prepare(dev_file, lab2ind, content_col, label_col,max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cliSLdgTcSvB"
      },
      "outputs": [],
      "source": [
        "test_inputs, test_labels = data_prepare(test_file, lab2ind, content_col, label_col,max_seq_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ovhuwDwErk1Q"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "URL = \"https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ar.300.vec.gz\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j60q3R1PsJfe"
      },
      "outputs": [],
      "source": [
        "FILE = \"fastText\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GDbBJuk9q2xT"
      },
      "outputs": [],
      "source": [
        "if os.path.isdir(FILE):\n",
        "    print(\"fastText exists.\")\n",
        "else:\n",
        "    !wget -P $FILE $URL\n",
        "    with gzip.open( 'fastText/cc.ar.300.vec.gz', 'rb') as f_in:\n",
        "            with open( 'fastText/cc.ar.300.vec', 'wb') as f_out:\n",
        "                shutil.copyfileobj(f_in, f_out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S1kY3gZjO2RE"
      },
      "outputs": [],
      "source": [
        "bert = AutoModel.from_pretrained('UBC-NLP/MARBERT')\n",
        "tokenizer = BertTokenizerFast.from_pretrained('UBC-NLP/MARBERT')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wTss_JpFryLi"
      },
      "outputs": [],
      "source": [
        "if torch.cuda.is_available():       \n",
        "    device = torch.device(\"cuda\")\n",
        "    print(f'There are {torch.cuda.device_count()} GPU(s) available.')\n",
        "    print('Device name:', torch.cuda.get_device_name(0))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "39tLH_tKzam9"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/gdrive/MyDrive/Master/Dataset/TrainingData/train.Ar.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzPPOrVQWiW5"
      },
      "outputs": [],
      "source": [
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "676DPU1BOPdp"
      },
      "outputs": [],
      "source": [
        "df['sarcastic'].value_counts(normalize = True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jgCgCF2Kf0T8"
      },
      "outputs": [],
      "source": [
        "df_train = pd.read_csv(\"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_train.csv\")\n",
        "df_train.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test3 = pd.read_csv(test_file3)\n",
        "df_test3.head()"
      ],
      "metadata": {
        "id": "7EwFBxvkCDXx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f1Vsi-GMf5S2"
      },
      "outputs": [],
      "source": [
        "df_test = pd.read_csv(\"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_test2.csv\")\n",
        "df_test.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_test2 = pd.read_csv(\"./isarcastic/task_A_AR_test.csv\")\n",
        "df_test2.head()"
      ],
      "metadata": {
        "id": "4Klm9K_clHhR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jNGazMCjf6My"
      },
      "outputs": [],
      "source": [
        "df_val = pd.read_csv(\"/gdrive/MyDrive/Master/Dataset/isarcastic/isarcastic_Ar_train_test/isarcastic_Ar_test1.csv\")\n",
        "df_val.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKfWnApvOoE7"
      },
      "source": [
        "# Split train dataset into train, validation and test sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u-aFgrYxXNYf"
      },
      "outputs": [],
      "source": [
        "text_temp = df['tweet']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IXGtt4W3jph8"
      },
      "outputs": [],
      "source": [
        "train_text, train_labels = df_train['tweet'], df_train['sarcastic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZRUAUmIojw08"
      },
      "outputs": [],
      "source": [
        "test_text, test_labels = df_test['tweet'], df_test['sarcastic']"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_text2 = df_test2['text']"
      ],
      "metadata": {
        "id": "s7-ovFSgmNwX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_text03, test_text13 = df_test3['text_0'], df_test3['text_1']"
      ],
      "metadata": {
        "id": "TB7iCWPoCLzp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_o-1rnOMj2Ej"
      },
      "outputs": [],
      "source": [
        "val_text, val_labels = df_val['tweet'], df_val['sarcastic']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P4lWRU30j9Ie"
      },
      "outputs": [],
      "source": [
        "len(train_text), len(val_text), len(test_text), len(val_labels), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QoqrSW41pTQ"
      },
      "outputs": [],
      "source": [
        "len(train_text), len(val_text), len(test_text), len(val_labels), len(test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CxI91JsrelLl"
      },
      "outputs": [],
      "source": [
        "train_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_zOKeOMeO-DT"
      },
      "outputs": [],
      "source": [
        "# sample data\n",
        "text = [\"this is a bert model tutorial\", \"we will fine-tune a bert model\"]\n",
        "\n",
        "# encode text\n",
        "sent_id = tokenizer.batch_encode_plus(text, padding=True, return_token_type_ids=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAH73n39PHLw"
      },
      "outputs": [],
      "source": [
        "# output\n",
        "print(sent_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tqmbgN-kwUU"
      },
      "source": [
        "# Length of train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yKwbpeN_PMiu"
      },
      "outputs": [],
      "source": [
        "seq_len = [len(i.split()) for i in text_temp]\n",
        "\n",
        "pd.Series(seq_len).hist(bins = 30)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MGch43U5Oyv"
      },
      "outputs": [],
      "source": [
        "max(seq_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OXcswEIRPvGe"
      },
      "outputs": [],
      "source": [
        "max_seq_len = 64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tk5S7DWaP2t6"
      },
      "outputs": [],
      "source": [
        "# tokenize and encode sequences in the training set\n",
        "tokens_train = tokenizer.batch_encode_plus(\n",
        "    train_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the validation set\n",
        "tokens_val = tokenizer.batch_encode_plus(\n",
        "    val_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")\n",
        "\n",
        "# tokenize and encode sequences in the test set\n",
        "tokens_test = tokenizer.batch_encode_plus(\n",
        "    test_text.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_test2 = tokenizer.batch_encode_plus(\n",
        "    test_text2.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "5XKKbO7BmbP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_test03 = tokenizer.batch_encode_plus(\n",
        "    test_text03.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "m-aJiooMCjVo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_test13 = tokenizer.batch_encode_plus(\n",
        "    test_text13.tolist(),\n",
        "    max_length = max_seq_len,\n",
        "    pad_to_max_length=True,\n",
        "    truncation=True,\n",
        "    return_token_type_ids=False\n",
        ")"
      ],
      "metadata": {
        "id": "84zkvvVoCnzB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_test03"
      ],
      "metadata": {
        "id": "I9VBg5tOmhRP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yj5qqxzsQbYw"
      },
      "outputs": [],
      "source": [
        "tokens_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QR-lXwmzQPd6"
      },
      "outputs": [],
      "source": [
        "# for train set\n",
        "train_seq = torch.tensor(tokens_train['input_ids'])\n",
        "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
        "train_y = torch.tensor(train_labels.tolist())\n",
        "\n",
        "# for validation set\n",
        "val_seq = torch.tensor(tokens_val['input_ids'])\n",
        "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
        "val_y = torch.tensor(val_labels.tolist())\n",
        "\n",
        "# for test set\n",
        "test_seq = torch.tensor(tokens_test['input_ids'])\n",
        "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
        "test_y = torch.tensor(test_labels.tolist())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq2 = torch.tensor(tokens_test2['input_ids'])\n",
        "test_mask2 = torch.tensor(tokens_test2['attention_mask'])"
      ],
      "metadata": {
        "id": "Il3naMaAmmMH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq03 = torch.tensor(tokens_test03['input_ids'])\n",
        "test_mask03 = torch.tensor(tokens_test03['attention_mask'])"
      ],
      "metadata": {
        "id": "eeGD3gqpCvf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_seq13 = torch.tensor(tokens_test13['input_ids'])\n",
        "test_mask13 = torch.tensor(tokens_test13['attention_mask'])"
      ],
      "metadata": {
        "id": "vFCftsPbC0dF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_seq13)"
      ],
      "metadata": {
        "id": "Fz2tg-kYC6CX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "moT1bQE3mPQE"
      },
      "source": [
        "# Remove sampler used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rm3pjKPVlrxy"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
        "train_dataloader2 = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
        "val_dataloader2 = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "test_data = TensorDataset(test_seq, test_mask, test_y)\n",
        "test_dataloader2 = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "test_data2 = TensorDataset(test_seq2, test_mask2)\n",
        "test_dataloader22 = DataLoader(test_data2, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data03 = TensorDataset(test_seq03, test_mask03)\n",
        "test_dataloader03 = DataLoader(test_data03, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-CDUMwOYC9xv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data13 = TensorDataset(test_seq13, test_mask13)\n",
        "test_dataloader13 = DataLoader(test_data13, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "-pn2OuBTDE2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3JuP4OAmhlt"
      },
      "source": [
        "# *build dataloader 1*\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AhM9v_f6nkpK"
      },
      "outputs": [],
      "source": [
        "word2idx = {}\n",
        "# Add <pad> and <unk> tokens to the vocabulary\n",
        "word2idx['<pad>'] = 0\n",
        "word2idx['<unk>'] = 1\n",
        "\n",
        "\n",
        "# Building our vocab from the corpus starting from index 2\n",
        "idx = 2\n",
        "# max_len = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-Wsi0QjzOWa"
      },
      "outputs": [],
      "source": [
        "def tokenize(texts, idx,max_len):\n",
        "    \"\"\"Tokenize texts, build vocabulary and find maximum sentence length.\n",
        "    \n",
        "    Args:\n",
        "        texts (List[str]): List of text data\n",
        "    \n",
        "    Returns:\n",
        "        tokenized_texts (List[List[str]]): List of list of tokens\n",
        "        word2idx (Dict): Vocabulary built from the corpus\n",
        "        max_len (int): Maximum sentence length\n",
        "    \"\"\"\n",
        "    \n",
        "    tokenized_texts = []\n",
        "    for sent in texts:\n",
        "        tokenized_sent = word_tokenize(sent)\n",
        "\n",
        "        tokenized_texts.append(tokenized_sent)\n",
        "\n",
        "        # Add new token to `word2idx`\n",
        "        for token in tokenized_sent:\n",
        "            if token not in word2idx:\n",
        "                word2idx[token] = idx\n",
        "                idx += 1\n",
        "\n",
        "\n",
        "    return tokenized_texts, idx,max_len\n",
        "\n",
        "def encode(tokenized_texts, word2idx, max_len):\n",
        "    input_ids = []\n",
        "    for tokenized_sent in tokenized_texts:\n",
        "        tokenized_sent += ['<pad>'] * (max_len - len(tokenized_sent))\n",
        "\n",
        "        # Encode tokens to input_ids\n",
        "        input_id = [word2idx.get(token) for token in tokenized_sent]\n",
        "        input_ids.append(input_id)\n",
        "    \n",
        "    return np.array(input_ids)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OB9FeeRqn6DR"
      },
      "outputs": [],
      "source": [
        "def load_pretrained_vectors(word2idx, fname):\n",
        "    print(\"Loading pretrained vectors...\")\n",
        "    fin = open(fname, 'r', encoding='utf-8', newline='\\n', errors='ignore')\n",
        "    n, d = map(int, fin.readline().split())\n",
        "\n",
        "    # Initilize random embeddings\n",
        "    embeddings = np.random.uniform(-0.25, 0.25, (len(word2idx), d))\n",
        "    embeddings[word2idx['<pad>']] = np.zeros((d,))\n",
        "\n",
        "    # Load pretrained vectors\n",
        "    count = 0\n",
        "    for line in tqdm_notebook(fin):\n",
        "        tokens = line.rstrip().split(' ')\n",
        "        word = tokens[0]\n",
        "        if word in word2idx:\n",
        "            count += 1\n",
        "            embeddings[word2idx[word]] = np.array(tokens[1:], dtype=np.float32)\n",
        "\n",
        "    print(f\"There are {count} / {len(word2idx)} pretrained vectors found.\")\n",
        "\n",
        "    return embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2jsZAppNdZwZ"
      },
      "outputs": [],
      "source": [
        "max_len =64"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kcYcQibGwEJg"
      },
      "outputs": [],
      "source": [
        "print(\"Tokenizing...\\n\")\n",
        "tokenized_texts_train,idx,max_len = tokenize(train_inputs, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uilA-ZC2EuR"
      },
      "outputs": [],
      "source": [
        "idx,max_len "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QCblUeLoVBDM"
      },
      "outputs": [],
      "source": [
        "input_ids_train = encode(tokenized_texts_train, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f2OJLlMT2RoR"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_val,idx,max_len = tokenize(validation_inputs, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JEZjKovopI9n"
      },
      "outputs": [],
      "source": [
        "input_ids_val = encode(tokenized_texts_val, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1UEQmlhcJLg"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_test,idx,max_len = tokenize(test_inputs, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R_ljzQVwb-GI"
      },
      "outputs": [],
      "source": [
        "input_ids_test = encode(tokenized_texts_test, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "H6N_dPXEDUHL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_8yvwQgdDUkG"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_test03,idx,max_len = tokenize(test_inputs03, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "93BP2zF-DUkL"
      },
      "outputs": [],
      "source": [
        "input_ids_test03 = encode(tokenized_texts_test03, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "XEzmF_yJDdOS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vg9KnjbrDdm8"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_test13,idx,max_len = tokenize(test_inputs13, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iiRF1Y8_Ddm_"
      },
      "outputs": [],
      "source": [
        "input_ids_test13 = encode(tokenized_texts_test13, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2wJk1GgrnF89"
      },
      "outputs": [],
      "source": [
        "tokenized_texts_test2,idx,max_len = tokenize(test_inputs2, idx,max_len)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_texts_test2"
      ],
      "metadata": {
        "id": "AD87WDPNnN26"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FXu8Zp9HnF8_"
      },
      "outputs": [],
      "source": [
        "input_ids_test2 = encode(tokenized_texts_test2, word2idx, max_len)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DctpztMIlgtt"
      },
      "outputs": [],
      "source": [
        "# Load pretrained vectors\n",
        "embeddings = load_pretrained_vectors(word2idx, \"fastText/cc.ar.300.vec\")\n",
        "embeddings = torch.tensor(embeddings)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nv_pbZr1pyMi"
      },
      "outputs": [],
      "source": [
        "14375 / 16263 *100.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_inputs"
      ],
      "metadata": {
        "id": "Ifjso1oOILmm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z9ZE2-w-pL9N"
      },
      "outputs": [],
      "source": [
        "def data_loader(train_inputs, val_inputs, test_inputs, train_labels, val_labels, test_labels,test_inputs2,  test_inputs03,test_inputs13\n",
        "               , batch_size=batch_size):\n",
        "\n",
        "    # Convert data type to torch.Tensor\n",
        "    train_inputs, val_inputs,test_inputs, train_labels, val_labels, test_labels,test_inputs2, test_inputs03,test_inputs13 =\\\n",
        "    tuple(torch.tensor(data) for data in\n",
        "          [train_inputs, val_inputs,test_inputs, train_labels, val_labels, test_labels,test_inputs2, test_inputs03,test_inputs13])\n",
        "\n",
        "    batch_size = batch_size\n",
        "\n",
        "    train_data = TensorDataset(train_inputs, train_labels)\n",
        "    train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
        "\n",
        "    # Create DataLoader for validation data\n",
        "    val_data = TensorDataset(val_inputs, val_labels)\n",
        "    val_dataloader = DataLoader(val_data, batch_size=batch_size)\n",
        "\n",
        "    test_data = TensorDataset(test_inputs, test_labels)\n",
        "    test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "    test_data2 = TensorDataset(test_inputs2)\n",
        "    test_dataloader12 = DataLoader(test_data2, batch_size=batch_size)\n",
        "\n",
        "    test_data03 = TensorDataset(test_inputs03)\n",
        "    test_dataloader103 = DataLoader(test_data03, batch_size=batch_size)\n",
        "    test_data13 = TensorDataset(test_inputs13)\n",
        "    test_dataloader113 = DataLoader(test_data13, batch_size=batch_size)\n",
        "\n",
        "    return train_dataloader, val_dataloader, test_dataloader, test_dataloader12, test_dataloader103, test_dataloader113"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eCQRLKNZ-t7"
      },
      "outputs": [],
      "source": [
        "train_dataloader, val_dataloader, test_dataloader,test_dataloader12, test_dataloader103, test_dataloader113 = \\\n",
        "data_loader( input_ids_train, input_ids_val, input_ids_test, train_labels, validation_labels, test_labels, input_ids_test2,  test_inputs03,test_inputs13, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_dataloader12)"
      ],
      "metadata": {
        "id": "jN304R4ouj7r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nw4W1iEDrAi6"
      },
      "source": [
        "# CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FqsrL0XToAPm"
      },
      "source": [
        "**CNN Architecture**\n",
        "\n",
        "The picture below is the illustration of the CNN architecture that we are going to build with three filter sizes: 2, 3, and 4, each of which has 2 filters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rV15G29uqLVX"
      },
      "source": [
        "![](https://github.com/chriskhanhtran/CNN-Sentence-Classification-PyTorch/blob/master/cnn-architecture.JPG?raw=true)\n",
        "\n",
        "*CNN Architecture (Source: Zhang, 2015)*\n",
        "\n",
        "```python\n",
        "# Sample configuration:\n",
        "filter_sizes = [2, 3, 4]\n",
        "num_filters = [2, 2, 2]\n",
        "```\n",
        "\n",
        "Suppose that we are classifying the sentence \"***I like this movie very much!***\" ($N = 7$ tokens) and the dimensionality of word vectors is $d=5$. After applying the embedding layer on the input token ids, the sample sentence is presented as a 2D tensor with shape (7, 5) like an image.\n",
        "\n",
        "$$\\mathrm{x_{emb}} \\quad \\in \\mathbb{R}^{7 \\times 5}$$\n",
        "\n",
        "We then use 1-dimesional convolution to extract features from the sentence. In this example, we have 6 filters in total, and each filter has shape $(f_i, d)$ where $f_i$ is the filter size for $i \\in \\{1,...,6\\}$. Each filter will then scan over $\\mathrm{x_{emb}}$ and returns a feature map:\n",
        "\n",
        "$$\\mathrm{x_{conv_ i} = Conv1D(x_{emb})} \\quad \\in \\mathbb{R}^{N-f_i+1}$$\n",
        "\n",
        "Next, we apply the ReLU activation to $\\mathrm{x_{conv_{i}}}$ and use max-over-time-pooling to reduce each feature map to a single scalar. Then we concatenate these scalars into the final feature vector which will be fed to a fully connected layer to compute the final scores for our classes (logits).\n",
        "\n",
        "$$\\mathrm{x_{pool_i} = MaxPool(ReLU(x_{conv_i}))} \\quad \\in \\mathbb{R}$$\n",
        "\n",
        "$$\\mathrm{x_{fc} = \\texttt{concat}(x_{pool_i})} \\quad \\in \\mathbb{R}^6$$\n",
        "\n",
        "The idea here is that each filter will capture different semantic signals in the sentence (ie. happiness, humor, politic, anger...) and max-pooling will record only the strongest signal over the sentence. This logic makes sense because humans also perceive the sentiment of a sentence based on its strongest word/signal.\n",
        "\n",
        "Finally, we use a fully connected layer with the weight matrix $\\mathbf{W_{fc}} \\in \\mathbb{R}^{2 \\times 6} $ and dropout to compute $\\mathrm{logits}$, which is a vector of length 2 that keeps the scores for 2 classes.\n",
        "\n",
        "$$\\mathrm{logits = Dropout(\\mathbf{W_{fc}}x_{fc})}  \\in \\mathbb{R}^2$$\n",
        "\n",
        "An in-depth explanation of CNN can be found in this [article](https://cs231n.github.io/convolutional-networks/) and this [video](https://www.youtube.com/watch?v=YRhxdVk_sIs).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MgLt4c-0iWKL"
      },
      "source": [
        "### 3.1. Create CNN Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmMXZ6UG9to8"
      },
      "source": [
        "For simplicity, the model above has very small configurations. The final model we'll use is much bigger but has the same architecture:\n",
        "\n",
        "|Description         |Values           |\n",
        "|:------------------:|:---------------:|\n",
        "|input word vectors  |fastText         |\n",
        "|embedding size      |300              |\n",
        "|filter sizes        |(3, 4, 5)        |\n",
        "|num filters         |(100, 100, 100)  |\n",
        "|activation          |ReLU             |\n",
        "|pooling             |1-max pooling    |\n",
        "|dropout rate        |0.5              |\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejGLw8TKViBY"
      },
      "outputs": [],
      "source": [
        "class CNN_NLP(nn.Module):\n",
        "    \"\"\"An 1D Convulational Neural Network for Sentence Classification.\"\"\"\n",
        "    def __init__(self,\n",
        "                 pretrained_embedding=None,\n",
        "                 freeze_embedding=False,\n",
        "                 vocab_size=None,\n",
        "                 embed_dim=300,\n",
        "                 filter_sizes=[3, 4, 5],\n",
        "                 num_filters=[100, 100, 100],\n",
        "                 num_classes=2,\n",
        "                 dropout=0.5):\n",
        "        \"\"\"\n",
        "        The constructor for CNN_NLP class.\n",
        "\n",
        "        Args:\n",
        "            pretrained_embedding (torch.Tensor): Pretrained embeddings with\n",
        "                shape (vocab_size, embed_dim)\n",
        "            freeze_embedding (bool): Set to False to fine-tune pretraiend\n",
        "                vectors. Default: False\n",
        "            vocab_size (int): Need to be specified when not pretrained word\n",
        "                embeddings are not used.\n",
        "            embed_dim (int): Dimension of word vectors. Need to be specified\n",
        "                when pretrained word embeddings are not used. Default: 300\n",
        "            filter_sizes (List[int]): List of filter sizes. Default: [3, 4, 5]\n",
        "            num_filters (List[int]): List of number of filters, has the same\n",
        "                length as `filter_sizes`. Default: [100, 100, 100]\n",
        "            n_classes (int): Number of classes. Default: 2\n",
        "            dropout (float): Dropout rate. Default: 0.5\n",
        "        \"\"\"\n",
        "\n",
        "        super(CNN_NLP, self).__init__()\n",
        "        # Embedding layer\n",
        "        if pretrained_embedding is not None:\n",
        "            self.vocab_size, self.embed_dim = pretrained_embedding.shape\n",
        "            self.embedding = nn.Embedding.from_pretrained(pretrained_embedding,\n",
        "                                                          freeze=freeze_embedding)\n",
        "        else:\n",
        "            self.embed_dim = embed_dim\n",
        "            self.embedding = nn.Embedding(num_embeddings=vocab_size,\n",
        "                                          embedding_dim=self.embed_dim,\n",
        "                                          padding_idx=0,\n",
        "                                          max_norm=5.0)\n",
        "        # Conv Network\n",
        "        self.conv1d_list = nn.ModuleList([\n",
        "            nn.Conv1d(in_channels=self.embed_dim,\n",
        "                      out_channels=num_filters[i],\n",
        "                      kernel_size=filter_sizes[i])\n",
        "            for i in range(len(filter_sizes))\n",
        "        ])\n",
        "        # Fully-connected layer and Dropout\n",
        "        self.fc = nn.Linear(np.sum(num_filters), num_classes)\n",
        "        self.dropout = nn.Dropout(p=dropout)\n",
        "\n",
        "    def forward(self, input_ids):\n",
        "        \"\"\"Perform a forward pass through the network.\n",
        "\n",
        "        Args:\n",
        "            input_ids (torch.Tensor): A tensor of token ids with shape\n",
        "                (batch_size, max_sent_length)\n",
        "\n",
        "        Returns:\n",
        "            logits (torch.Tensor): Output logits with shape (batch_size,\n",
        "                n_classes)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings from `input_ids`. Output shape: (b, max_len, embed_dim)\n",
        "        x_embed = self.embedding(input_ids).float()\n",
        "\n",
        "        # Permute `x_embed` to match input shape requirement of `nn.Conv1d`.\n",
        "        # Output shape: (b, embed_dim, max_len)\n",
        "        x_reshaped = x_embed.permute(0, 2, 1)\n",
        "\n",
        "        # Apply CNN and ReLU. Output shape: (b, num_filters[i], L_out)\n",
        "        x_conv_list = [F.relu(conv1d(x_reshaped)) for conv1d in self.conv1d_list]\n",
        "\n",
        "        # Max pooling. Output shape: (b, num_filters[i], 1)\n",
        "        x_pool_list = [F.max_pool1d(x_conv, kernel_size=x_conv.shape[2])\n",
        "            for x_conv in x_conv_list]\n",
        "        \n",
        "        # Concatenate x_pool_list to feed the fully connected layer.\n",
        "        # Output shape: (b, sum(num_filters))\n",
        "        x_fc = torch.cat([x_pool.squeeze(dim=2) for x_pool in x_pool_list],\n",
        "                         dim=1)\n",
        "        \n",
        "        # Compute logits. Output shape: (b, n_classes)\n",
        "        logits = self.fc(self.dropout(x_fc))\n",
        "\n",
        "        return logits"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nf9xEQR-yO_U"
      },
      "source": [
        "### 3.2. Optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7TnaJvUCaz7"
      },
      "source": [
        "To train Deep Learning models, we need to define a loss function and minimize this loss. We'll use back-propagation to compute gradients and use an optimization algorithm (ie. Gradient Descent) to minimize the loss. The original paper used the Adadelta optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lTJnvDI9xuUv"
      },
      "outputs": [],
      "source": [
        "\n",
        "def initilize_model(pretrained_embedding=None,\n",
        "                    freeze_embedding=False,\n",
        "                    vocab_size=None,\n",
        "                    embed_dim=300,\n",
        "                    filter_sizes=[3, 4, 5],\n",
        "                    num_filters=[100, 100, 100],\n",
        "                    num_classes=2,\n",
        "                    dropout=0.5,\n",
        "                    learning_rate=0.01):\n",
        "    \"\"\"Instantiate a CNN model and an optimizer.\"\"\"\n",
        "\n",
        "    assert (len(filter_sizes) == len(num_filters)), \"filter_sizes and \\\n",
        "    num_filters need to be of the same length.\"\n",
        "\n",
        "    # Instantiate CNN model\n",
        "    cnn_model = CNN_NLP(pretrained_embedding=pretrained_embedding,\n",
        "                        freeze_embedding=freeze_embedding,\n",
        "                        vocab_size=vocab_size,\n",
        "                        embed_dim=embed_dim,\n",
        "                        filter_sizes=filter_sizes,\n",
        "                        num_filters=num_filters,\n",
        "                        num_classes=2,\n",
        "                        dropout=0.5)\n",
        "    \n",
        "    # Send model to `device` (GPU/CPU)\n",
        "    cnn_model.to(device)\n",
        "\n",
        "    # Instantiate Adadelta optimizer\n",
        "    optimizer = optim.Adadelta(cnn_model.parameters(),\n",
        "                               lr=learning_rate,\n",
        "                               rho=0.95)\n",
        "\n",
        "    return cnn_model, optimizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyWHu4sr55lU"
      },
      "source": [
        "### 3.3. Training Loop"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9iWapM27CVw3"
      },
      "source": [
        "For each epoch, the code below will perform a forward step to compute the *Cross Entropy* loss, a backward step to compute gradients and use the optimizer to update weights/parameters. At the end of each epoch, the loss on training data and the accuracy over the validation data will be printed to help us keep track of the model's performance. The code is heavily annotated with detailed explanations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RzRabj3zcvma"
      },
      "outputs": [],
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "97SKeTLcX094"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# Specify loss function\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "def set_seed(seed_value=42):\n",
        "    \"\"\"Set seed for reproducibility.\"\"\"\n",
        "\n",
        "    random.seed(seed_value)\n",
        "    np.random.seed(seed_value)\n",
        "    torch.manual_seed(seed_value)\n",
        "    torch.cuda.manual_seed_all(seed_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fyztTDP_X-lD"
      },
      "outputs": [],
      "source": [
        "def train(model, optimizer, train_dataloader, val_dataloader=None, epochs=10):\n",
        "    \"\"\"Train the CNN model.\"\"\"\n",
        "    \n",
        "    # Tracking best validation accuracy\n",
        "    best_accuracy = 0\n",
        "    best_f1_sarcastic = 0\n",
        "\n",
        "    # Start training loop\n",
        "    \n",
        "    print(\"Start training...\\n\")\n",
        "    print(f\"{'Epoch':^7} | {'Train Loss':^12} | {'Val Loss':^10} | {\\\n",
        "    'Val Acc':^9} | {'f1 sarcastic':^9}| {'Elapsed':^9}\")\n",
        "    print(\"-\"*60)\n",
        "\n",
        "    for epoch_i in range(epochs):\n",
        "        # =======================================\n",
        "        #               Training\n",
        "        # =======================================\n",
        "\n",
        "        # Tracking time and loss\n",
        "        t0_epoch = time.time()\n",
        "        total_loss = 0\n",
        "\n",
        "        # Put the model into the training mode\n",
        "        model.train()\n",
        "\n",
        "        for step, batch in enumerate(train_dataloader):\n",
        "            # Load batch to GPU\n",
        "            b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "            # Zero out any previously calculated gradients\n",
        "            model.zero_grad()\n",
        "\n",
        "            # Perform a forward pass. This will return logits.\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "            # Compute loss and accumulate the loss values\n",
        "            loss = loss_fn(logits, b_labels)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            # Perform a backward pass to calculate gradients\n",
        "            loss.backward()\n",
        "\n",
        "            # Update parameters\n",
        "            optimizer.step()\n",
        "\n",
        "        # Calculate the average loss over the entire training data\n",
        "        avg_train_loss = total_loss / len(train_dataloader)\n",
        "\n",
        "        # =======================================\n",
        "        #               Evaluation\n",
        "        # =======================================\n",
        "        if val_dataloader is not None:\n",
        "            # After the completion of each training epoch, measure the model's\n",
        "            # performance on our validation set.\n",
        "            val_loss, val_accuracy,val_f1_sarcastic, preds_all = evaluate(model, val_dataloader)\n",
        "\n",
        "            # Track the best accuracy\n",
        "            # if val_accuracy > best_accuracy:\n",
        "            #     best_accuracy = val_accuracy\n",
        "            if val_f1_sarcastic > best_f1_sarcastic:\n",
        "                best_f1_sarcastic = val_f1_sarcastic\n",
        "            \n",
        "\n",
        "            # Print performance over the entire training data\n",
        "            time_elapsed = time.time() - t0_epoch\n",
        "            print(f\"{epoch_i + 1:^7} | {avg_train_loss:^12.6f} | {\\\n",
        "            val_loss:^10.6f} | {val_accuracy:^9.2f} | {val_f1_sarcastic:^9.2f}|{time_elapsed:^9.2f}\")\n",
        "            # print(f\"Training complete! Best f1_sarcastic: {best_f1_sarcastic:.2f}%.\")\n",
        "            \n",
        "    print(\"\\n\")\n",
        "    print(f\"Training complete! Best f1_sarcastic: {best_f1_sarcastic:.2f}%.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NaW2V4O225fS"
      },
      "outputs": [],
      "source": [
        "def evaluate(model, val_dataloader):\n",
        "    \"\"\"After the completion of each training epoch, measure the model's\n",
        "    performance on our validation set.\n",
        "    \"\"\"\n",
        "    # Put the model into the evaluation mode. The dropout layers are disabled\n",
        "    # during the test time.\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables\n",
        "    val_accuracy = []\n",
        "    val_loss = []\n",
        "    preds_all = []\n",
        "    val_f1_sarcastic = []\n",
        "\n",
        "    # For each batch in our validation set...\n",
        "    for batch in val_dataloader:\n",
        "        # Load batch to GPU\n",
        "        b_input_ids, b_labels = tuple(t.to(device) for t in batch)\n",
        "\n",
        "        # Compute logits\n",
        "        with torch.no_grad():\n",
        "            logits = model(b_input_ids)\n",
        "\n",
        "        # Compute loss\n",
        "        loss = loss_fn(logits, b_labels)\n",
        "        val_loss.append(loss.item())\n",
        "\n",
        "        # Get the predictions\n",
        "        preds = torch.argmax(logits, dim=1).flatten()\n",
        "        preds_all.extend(preds)\n",
        "\n",
        "        # Calculate the accuracy rate\n",
        "        accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
        "        val_accuracy.append(accuracy)\n",
        "        # print(len(b_labels))\n",
        "        # print(len(preds))\n",
        "        f1_sarcastic = f1_score(b_labels.cpu().detach().numpy(), preds.cpu().detach().numpy(), average='binary', pos_label=1) \n",
        "        val_f1_sarcastic.append(f1_sarcastic)\n",
        "\n",
        "\n",
        "    # Compute the average accuracy and loss over the validation set.\n",
        "    val_loss = np.mean(val_loss)\n",
        "    val_accuracy = np.mean(val_accuracy)\n",
        "    val_f1_sarcastic = np.mean(val_f1_sarcastic)\n",
        "\n",
        "    return val_loss, val_accuracy, val_f1_sarcastic, preds_all"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DDfo7nBI4I2L"
      },
      "outputs": [],
      "source": [
        "# CNN-non-static: fastText pretrained word vectors are fine-tuned during training.\n",
        "set_seed(42)\n",
        "cnn_non_static, optimizer = initilize_model(pretrained_embedding=embeddings,\n",
        "                                            freeze_embedding=False,\n",
        "                                            learning_rate=0.25,\n",
        "                                            dropout=0.25)\n",
        "train(cnn_non_static, optimizer, train_dataloader, val_dataloader, epochs=20)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HflO2JuLWdLt"
      },
      "outputs": [],
      "source": [
        "test_loss, test_accuracy,test_f1_sarcastic,preds = evaluate(cnn_non_static, test_dataloader)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dxnw59klhke8"
      },
      "outputs": [],
      "source": [
        "test_f1_sarcastic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9u0m0wt89g1i"
      },
      "outputs": [],
      "source": [
        "cnn_non_static"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IgbfpnzvXxiv"
      },
      "outputs": [],
      "source": [
        "l =torch.zeros([len(preds)], dtype=torch.int32)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lXw4W8SFXbYD"
      },
      "outputs": [],
      "source": [
        "i=0\n",
        "for x in preds:\n",
        "  l[i] = x.item()\n",
        "  i= i+1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "joPXFFvEYaYD"
      },
      "outputs": [],
      "source": [
        "preds = l"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJsIz4EpW_3A"
      },
      "outputs": [],
      "source": [
        "f1_sarcastic = f1_score(test_y, l, average='binary', pos_label=1) \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Xj98t9rlRE7"
      },
      "outputs": [],
      "source": [
        "f1score = f1_score(test_y, preds, average='macro') \n",
        "recall = recall_score(test_y, preds, average='macro')\n",
        "precision = precision_score(test_y, preds, average='macro')\n",
        "report = classification_report(test_y, preds)\n",
        "f1_sarcastic,f1score,recall,precision\n",
        "accuracy = accuracy_score(test_y, preds)\n",
        "# accuracy\n",
        "# report\n",
        "\n",
        "epoch_eval_results = {\n",
        "        \"accuracy\":accuracy, \"recall\":recall, \"precision\":precision, \"f1\":f1score, \"f1_sarcastic\":f1_sarcastic }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XsQI5a9olwbv"
      },
      "outputs": [],
      "source": [
        "report = \"./isarcasm/\"+\"_report.tsv\"\n",
        "sorted_report = \"./isarcasm/\"+\"_report_sorted.tsv\"\n",
        "if not os.path.exists(\"./isarcasm/\"):\n",
        "  os.mkdir(\"./isarcasm/\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrzgQcIjlwby"
      },
      "outputs": [],
      "source": [
        "report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJHheUZElwb2"
      },
      "outputs": [],
      "source": [
        "report_test = \"./isarcasm/\"+\"_report_test.tsv\"\n",
        "sorted_report_test = \"./isarcasm/\"+\"_report_test_sorted.tsv\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JDM-t-aPV_c4"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "with open(report_test,\"a\") as fOut:\n",
        "  fOut.write(json.dumps(epoch_eval_results)+\"\\n\")\n",
        "  fOut.flush()\n",
        "#------------------------------------\n",
        "report_df = pd.read_json(report_test, orient='records', lines=True)\n",
        "report_df.sort_values(by=[\"accuracy\"],ascending=False, inplace=True)\n",
        "report_df.to_csv(sorted_report_test,sep=\"\\t\",index=False)\n",
        "report_df.head(5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lGIxfCBFWun"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K2HZc5ZYRV28"
      },
      "source": [
        "# Freeze BERT Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wHZ0MC00RQA_"
      },
      "outputs": [],
      "source": [
        "# freeze all the parameters\n",
        "for param in bert.parameters():\n",
        "    param.requires_grad = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s7ahGBUWRi3X"
      },
      "source": [
        "# Define Model Architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b3iEtGyYRd0A"
      },
      "outputs": [],
      "source": [
        "class BERT_Arch(nn.Module):\n",
        "\n",
        "    def __init__(self, bert):\n",
        "      \n",
        "      super(BERT_Arch, self).__init__()\n",
        "\n",
        "      self.bert = bert \n",
        "      \n",
        "      # dropout layer\n",
        "      self.dropout = nn.Dropout(0.1)\n",
        "      \n",
        "      # relu activation function\n",
        "      self.relu =  nn.ReLU()\n",
        "\n",
        "      # dense layer 1\n",
        "      self.fc1 = nn.Linear(768,512)\n",
        "      \n",
        "      # dense layer 2 (Output layer)\n",
        "      self.fc2 = nn.Linear(512,2)\n",
        "\n",
        "      #softmax activation function\n",
        "      self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    #define the forward pass\n",
        "    def forward(self, sent_id, mask):\n",
        "\n",
        "      #pass the inputs to the model  \n",
        "      _, cls_hs = self.bert(sent_id, attention_mask=mask,  return_dict=False)\n",
        "      # print(\"cls_hs\", cls_hs)\n",
        "      x = self.fc1(cls_hs)\n",
        "\n",
        "      x = self.relu(x)\n",
        "\n",
        "      x = self.dropout(x)\n",
        "\n",
        "      # output layer\n",
        "      x = self.fc2(x)\n",
        "      \n",
        "      # apply softmax activation\n",
        "      x = self.softmax(x)\n",
        "\n",
        "      return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cBAJJVuJRliv"
      },
      "outputs": [],
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "model1 = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model1 = model1.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DG8q1n1_2Fyw"
      },
      "outputs": [],
      "source": [
        "model1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "taXS0IilRn9J"
      },
      "outputs": [],
      "source": [
        "\n",
        "# optimizer from hugging face transformers\n",
        "from transformers import AdamW\n",
        "\n",
        "# define the optimizer\n",
        "optimizer2 = AdamW(model1.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j9CDpoMQR_rK"
      },
      "source": [
        "# Find Class Weights"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tb2JbDJDvPhv"
      },
      "outputs": [],
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "izY5xH5eR7Ur"
      },
      "outputs": [],
      "source": [
        "\n",
        "#compute the class weights\n",
        "class_wts = compute_class_weight(class_weight = 'balanced', classes = np.unique(train_labels), y =  train_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbJnirwCvhg5"
      },
      "outputs": [],
      "source": [
        "print(class_wts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r1WvfY2vSGKi"
      },
      "outputs": [],
      "source": [
        "# convert class weights to tensor\n",
        "weights= torch.tensor(class_wts,dtype=torch.float)\n",
        "weights = weights.to(device)\n",
        "\n",
        "# loss function\n",
        "cross_entropy  = nn.NLLLoss(weight=weights) \n",
        "\n",
        "# number of training epochs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "My4CA0qaShLq"
      },
      "source": [
        "# Fine-Tune BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rskLk8R_SahS"
      },
      "outputs": [],
      "source": [
        "# function to train the model\n",
        "def train2(model):\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  total_labels=[]\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(train_dataloader2):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader2)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [r.to(device) for r in batch]\n",
        " \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer2.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "    total_labels.append(labels)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader2)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds, total_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGXovFDlSxB5"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate2(model, iterator):\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  # deactivate dropout layers\n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save the model predictions\n",
        "  total_preds = []\n",
        "  total_labels =[]\n",
        "  # iterate over batches\n",
        "  for step,batch in enumerate(iterator):\n",
        "    \n",
        "    # Progress update every 50 batches.\n",
        "    if step % 50 == 0 and not step == 0:\n",
        "      \n",
        "      # Calculate elapsed time in minutes.\n",
        "      # elapsed = format_time(time.time() - t0)\n",
        "            \n",
        "      # Report progress.\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(iterator)))\n",
        "\n",
        "    # push the batch to gpu\n",
        "    batch = [t.to(device) for t in batch]\n",
        "\n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # deactivate autograd\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      # model predictions\n",
        "      preds = model(sent_id, mask)\n",
        "\n",
        "      # compute the validation loss between actual and predicted values\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "      labels = labels.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "      total_labels.append(labels)\n",
        "\n",
        "  # compute the validation loss of the epoch\n",
        "  avg_loss = total_loss / len(iterator) \n",
        "\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  return avg_loss, total_preds, total_labels"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KZEgxRRTLXG"
      },
      "source": [
        "# Start Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k1USGTntS3TS"
      },
      "outputs": [],
      "source": [
        "# set initial loss to infinite\n",
        "best_valid_loss = float('inf')\n",
        "\n",
        "# empty lists to store training and validation loss of each epoch\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "epochs=6\n",
        "#for each epoch\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    #train model\n",
        "    train_loss, total_pred,total_labels = train2(model1)\n",
        "    \n",
        "    #evaluate model\n",
        "    valid_loss, val_pred,val_labels= evaluate2(model1,val_dataloader2)\n",
        "    \n",
        "    #save the best model\n",
        "    if valid_loss < best_valid_loss:\n",
        "        best_valid_loss = valid_loss\n",
        "        torch.save(model1.state_dict(), 'saved_weights.pt')\n",
        "    \n",
        "    # append training and validation loss\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ladhn_nLIxLh"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pneul56tIx7b"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "83BkDP8BIx7d"
      },
      "outputs": [],
      "source": [
        "#load weights of best model\n",
        "path = 'saved_weights.pt'\n",
        "model1.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zs3qc6xEIx7g"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fNcMkraBIx7h"
      },
      "outputs": [],
      "source": [
        "# get predictions for test data\n",
        "with torch.no_grad():\n",
        "  preds = model1(test_seq.to(device), test_mask.to(device))\n",
        "  preds = preds.detach().cpu().numpy()\n",
        "# model's performance\n",
        "preds = np.argmax(preds, axis = 1)\n",
        "print(classification_report(test_y, preds))\n",
        "\n",
        "# confusion matrix\n",
        "pd.crosstab(test_y, preds)\n",
        "\n",
        "f1_sarcastic = f1_score(test_y, preds, average='binary', pos_label=1) \n",
        "f1score = f1_score(test_y, preds, average='macro') \n",
        "recall = recall_score(test_y, preds, average='macro')\n",
        "precision = precision_score(test_y, preds, average='macro')\n",
        "report = classification_report(test_y, preds)\n",
        "print(f1_sarcastic,f1score,recall,precision)\n",
        "accuracy = accuracy_score(test_y, preds)\n",
        "print(accuracy)\n",
        "print(report)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jq2xo0iQv1o"
      },
      "source": [
        "# Ensemble"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XCwNSTv9QP3N"
      },
      "outputs": [],
      "source": [
        "class MyEnsemble(nn.Module):\n",
        "\n",
        "    def __init__(self, modelA, modelB, input):\n",
        "        super(MyEnsemble, self).__init__()\n",
        "        self.modelA = modelA\n",
        "        self.modelB = modelB\n",
        "        # self.modelC = modelC\n",
        "        self.fc1 = nn.Linear(input, 2)\n",
        "\n",
        "    def forward(self, sent_id, mask, b_input_ids):\n",
        "        out1 = self.modelA(b_input_ids)\n",
        "        out2 = self.modelB(sent_id, mask)\n",
        "        out = out1 + out2 \n",
        "        x = self.fc1(out)\n",
        "        return torch.softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YeZEADy7SSor"
      },
      "outputs": [],
      "source": [
        "model3 = MyEnsemble(cnn_non_static,model1, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JPs44l12TEgj"
      },
      "outputs": [],
      "source": [
        "# pass the pre-trained BERT to our define architecture\n",
        "# model2 = BERT_Arch(bert)\n",
        "\n",
        "# push the model to GPU\n",
        "model3 = model3.to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x15z62JYTEgn"
      },
      "outputs": [],
      "source": [
        "optimizer3 = AdamW(model3.parameters(), lr = 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "scN_-aMwD-9y"
      },
      "outputs": [],
      "source": [
        "def train3(model,optimizer):\n",
        "  \n",
        "  model.train()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  # empty list to save model predictions\n",
        "  total_preds=[]\n",
        "  \n",
        "  # iterate over batches\n",
        "  step = 0\n",
        "  for b1, b2 in zip(train_dataloader, train_dataloader2):\n",
        "    # print(f, b)\n",
        "\n",
        "  # for step,batch in enumerate(train_dataloader2):\n",
        "    \n",
        "    # progress update after every 50 batches.\n",
        "    if step % batch_size == 0 and not step == 0:\n",
        "      print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader2)))\n",
        "    step= step + 1\n",
        "\n",
        "    # push the batch to gpu\n",
        "    # batch = [r.to(device) for r in b1]\n",
        "    b_input_ids, b_labels = tuple(t.to(device) for t in b1)\n",
        "    batch = [r.to(device) for r in b2]\n",
        "     \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    # clear previously calculated gradients \n",
        "    model.zero_grad()        \n",
        "\n",
        "    # get model predictions for the current batch\n",
        "    preds = model(sent_id, mask,b_input_ids)\n",
        "\n",
        "    # compute the loss between actual and predicted values\n",
        "    loss = cross_entropy(preds, labels)\n",
        "\n",
        "    # add on to the total loss\n",
        "    total_loss = total_loss + loss.item()\n",
        "\n",
        "    # backward pass to calculate the gradients\n",
        "    loss.backward()\n",
        "\n",
        "    # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
        "    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "    # update parameters\n",
        "    optimizer3.step()\n",
        "\n",
        "    # model predictions are stored on GPU. So, push it to CPU\n",
        "    preds=preds.detach().cpu().numpy()\n",
        "\n",
        "    # append the model predictions\n",
        "    total_preds.append(preds)\n",
        "\n",
        "  # compute the training loss of the epoch\n",
        "  avg_loss = total_loss / len(train_dataloader)\n",
        "  \n",
        "  # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
        "  # reshape the predictions in form of (number of samples, no. of classes)\n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "\n",
        "  #returns the loss and predictions\n",
        "  return avg_loss, total_preds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3Pd8iB7_UFmE"
      },
      "outputs": [],
      "source": [
        "# function for evaluating the model\n",
        "def evaluate3(model,iter1,iter2):\n",
        "  \n",
        "  print(\"\\nEvaluating...\")\n",
        "  \n",
        "  model.eval()\n",
        "\n",
        "  total_loss, total_accuracy = 0, 0\n",
        "  \n",
        "  total_preds = []\n",
        "  total_labels = []\n",
        "  val_f1_sarcastic = []\n",
        "\n",
        "  for b1, b2 in zip(iter1, iter2):\n",
        "    # print(f, b)\n",
        "\n",
        " \n",
        "    b_input_ids, b_labels = tuple(t.to(device) for t in b1)\n",
        "    batch = [r.to(device) for r in b2]\n",
        "     \n",
        "    sent_id, mask, labels = batch\n",
        "\n",
        "    with torch.no_grad():\n",
        "      \n",
        "      preds = model(sent_id, mask,b_input_ids)\n",
        "      loss = cross_entropy(preds,labels)\n",
        "\n",
        "      total_loss = total_loss + loss.item()\n",
        "\n",
        "      preds = preds.detach().cpu().numpy()\n",
        "\n",
        "      total_preds.append(preds)\n",
        "      total_labels.append(labels)\n",
        "\n",
        "  avg_loss = total_loss / len(iter2)   \n",
        "  total_preds  = np.concatenate(total_preds, axis=0)\n",
        "  return avg_loss, total_preds,total_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f9Ho3wvwTgoN"
      },
      "outputs": [],
      "source": [
        "best_valid_loss = float('inf')\n",
        "best_val_f1_sarcastic = 0\n",
        "train_losses=[]\n",
        "valid_losses=[]\n",
        "epochs = 1\n",
        "for epoch in range(epochs):\n",
        "     \n",
        "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
        "    \n",
        "    train_loss, _ = train3(model3,optimizer3)\n",
        "    \n",
        "    valid_loss, total_preds,total_labels = evaluate3(model3,val_dataloader,val_dataloader2)\n",
        "    print(total_labels)\n",
        "    print(val_y)\n",
        "\n",
        "    total_preds = np.argmax(total_preds, axis = 1)\n",
        "\n",
        "    val_f1_sarcastic = f1_score(val_y, total_preds, average='binary', pos_label=1) \n",
        "\n",
        "    print(\"val_f1_sarcastic\", val_f1_sarcastic)\n",
        "    torch.save(model3.state_dict(), 'saved_weights2.pt')\n",
        "    train_losses.append(train_loss)\n",
        "    valid_losses.append(valid_loss)\n",
        "\n",
        "    \n",
        "    \n",
        "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
        "    print(f'Validation Loss: {valid_loss:.3f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_yrhUc9kTI5a"
      },
      "source": [
        "# Load Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OacxUyizS8d1"
      },
      "outputs": [],
      "source": [
        "path = 'saved_weights2.pt'\n",
        "model3.load_state_dict(torch.load(path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x4SVftkkTZXA"
      },
      "source": [
        "# Get Predictions for Test Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NZl0SZmFTRQA"
      },
      "outputs": [],
      "source": [
        "with torch.no_grad():\n",
        "  preds = model3(test_seq2.to(device), test_mask2.to(device),torch.tensor(input_ids_test2).to(device))\n",
        "  preds = preds.detach().cpu().numpy()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  preds = model3(test_seq03.to(device), test_mask03.to(device),torch.tensor(input_ids_test03).to(device))"
      ],
      "metadata": {
        "id": "GWXTmji0GRjb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ms1ObHZxTYSI"
      },
      "outputs": [],
      "source": [
        "preds = np.argmax(preds, axis = 1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YqzLS7rHTp4T"
      },
      "outputs": [],
      "source": [
        "pd.crosstab(test_y, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ai0QEw_RJj2I"
      },
      "outputs": [],
      "source": [
        "f1_sarcastic = f1_score(test_y, preds, average='binary', pos_label=1) \n",
        "f1score = f1_score(test_y, preds, average='macro') \n",
        "recall = recall_score(test_y, preds, average='macro')\n",
        "precision = precision_score(test_y, preds, average='macro')\n",
        "report = classification_report(test_y, preds)\n",
        "f1_sarcastic,f1score,recall,precision\n",
        "accuracy = accuracy_score(test_y, preds)\n",
        "epoch_eval_results = {\n",
        "        \"accuracy\":accuracy, \"recall\":recall, \"precision\":precision, \"f1\":f1score, \"f1_sarcastic\":f1_sarcastic }\n",
        "\n",
        "with open(report_test,\"a\") as fOut:\n",
        "  fOut.write(json.dumps(epoch_eval_results)+\"\\n\")\n",
        "  fOut.flush()\n",
        "#------------------------------------\n",
        "report_df = pd.read_json(report_test, orient='records', lines=True)\n",
        "report_df.sort_values(by=[\"accuracy\"],ascending=False, inplace=True)\n",
        "report_df.to_csv(sorted_report_test,sep=\"\\t\",index=False)\n",
        "report_df.head(5)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "-taY37yH3Q82"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/gdrive/MyDrive/Master/Dataset/TestingData/task_A_AR_test.csv\"  ./isarcastic/task_A_AR_test.csv"
      ],
      "metadata": {
        "id": "3WKN5J-s2_wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_prepare_BERT(file_path, lab2ind, tokenizer, content_col, label_col, MAX_LEN):\n",
        "  df = pd.read_csv(file_path, delimiter=',', header=0)\n",
        "  df = df[df[content_col].notnull()]\n",
        "  print(\"Data size \", df.shape)\n",
        "  sentences = df[content_col].values\n",
        "  sentences = [\"[CLS] \" + sentence+ \" [SEP]\" for sentence in sentences]\n",
        "  print (\"The first sentence:\")\n",
        "  print (sentences[0])\n",
        "  tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "  print (\"Tokenize the first sentence:\")\n",
        "  print (tokenized_texts[0])\n",
        "  input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "  print (\"Index numbers of the first sentence:\")\n",
        "  print (input_ids[0])\n",
        "  pad_ind = tokenizer.convert_tokens_to_ids(['[PAD]'])[0]\n",
        "  input_ids = pad_sequences(input_ids, maxlen=MAX_LEN+2, dtype=\"long\", truncating=\"post\", padding=\"post\", value=pad_ind)\n",
        "  print (\"Index numbers of the first sentence after padding:\\n\",input_ids[0])\n",
        "  attention_masks = []\n",
        "  for seq in input_ids:\n",
        "    seq_mask = [int(i > 0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "  inputs = torch.tensor(input_ids)\n",
        "  masks = torch.tensor(attention_masks)\n",
        "  return inputs, masks\n"
      ],
      "metadata": {
        "id": "3IFePNWMn5Pw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dev_file= \"isarcastic/task_A_AR_test.csv\" #dev file path or test file path"
      ],
      "metadata": {
        "id": "Fp7FSoLQ97no"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "content_col =\"text\""
      ],
      "metadata": {
        "id": "BqTsvP5B-Dmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_inputs, validation_masks = data_prepare_BERT(dev_file, lab2ind, tokenizer, content_col, label_col,max_seq_length)\n",
        "print (\"[INFO] step (6') Create an iterator of data with torch DataLoader.\")"
      ],
      "metadata": {
        "id": "3ovvGvSXobJR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validation_data = TensorDataset(validation_inputs, validation_masks)\n"
      ],
      "metadata": {
        "id": "XdeE_C-vofKi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#---------------------------\n",
        "validation_dataloader = DataLoader(validation_data, batch_size=batch_size)\n",
        "#------------------------------------------"
      ],
      "metadata": {
        "id": "5ECuMU8Foi5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def evaluate4(model, iterator, criterion):\n",
        "  model.eval()\n",
        "  epoch_loss = 0\n",
        "  all_pred=[]\n",
        "  with torch.no_grad():\n",
        "    for i, batch in enumerate(iterator):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      input_ids, input_mask = batch\n",
        "      outputs = model(input_ids, input_mask)\n",
        "      logits = outputs[0]\n",
        "      del batch, input_ids, input_mask\n",
        "      probabilities, predicted = torch.max(logits.cpu().data, 1)\n",
        "      all_pred.extend(predicted)\n",
        "\n",
        "  return all_pred\n",
        "\n"
      ],
      "metadata": {
        "id": "LD0QZWVuotk_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch = 6"
      ],
      "metadata": {
        "id": "QhZiv6PaLcOn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_all_pred = evaluate4(model3, validation_dataloader, criterion)"
      ],
      "metadata": {
        "id": "YU6HGZBjwWMO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ym7qZfqR4AHN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in test_all_pred:\n",
        "    print(i.item())"
      ],
      "metadata": {
        "id": "6wubinnUrNwc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "textfile = open(\"task_a_ar.txt\", \"w\")\n",
        "textfile.write(\"task_a_ar\" + \"\\n\")\n",
        "for i in preds:\n",
        "    textfile.write(str(i) + \"\\n\")\n",
        "textfile.close()"
      ],
      "metadata": {
        "id": "WMOFK-OesR-L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp    \"task_a_ar.txt\" /gdrive/MyDrive/Master/Dataset/Outputs/task_a_ar3.txt"
      ],
      "metadata": {
        "id": "szd03QSKuaAc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ha2FGrkA-eUL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp \"/gdrive/MyDrive/Master/Dataset/TestingData/task_C_AR_test.csv\"  ./isarcastic/task_C_AR_test.csv"
      ],
      "metadata": {
        "id": "ooyyfWKCr4JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# !cp 'MARBERT_pytorch_verison/vocab.txt' '/gdrive/MyDrive/Master/Dataset/isarcasticisarcastic_MARBERT_bert_ckpt/model_5/vocab.txt'"
      ],
      "metadata": {
        "id": "9bYwjTFbZK7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_file3 = 'isarcastic/task_C_AR_test.csv'"
      ],
      "metadata": {
        "id": "pqD6LcMFB8Qr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RN50DNeGdUFQ"
      },
      "outputs": [],
      "source": [
        "test_file3 = open('isarcastic/task_C_AR_test.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CCsdKpOddeFq"
      },
      "outputs": [],
      "source": [
        "csvreader = csv.reader(test_file3)\n",
        "header = next(csvreader)\n",
        "print(header)\n",
        "rows = []\n",
        "for row in csvreader:\n",
        "    rows.append(row)\n",
        "print(rows)\n",
        "test_file3.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uPIQgCPlADrM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "iSarcasmEval_Ensemble_Model.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}